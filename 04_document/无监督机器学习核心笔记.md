---
tags: 
alias: 
date: 2025-08-31 05:07
---
## 1. 什么是无监督学习？

无监督学习的核心思想是从**无标签数据 (Unlabeled Data)** 中自动发现隐藏的模式、结构和关联。它不依赖于预先定义的正确答案，而是让算法自行探索数据。

### 与监督学习的核心区别

|特性|**监督学习 (Supervised Learning)**|**无监督学习 (Unsupervised Learning)**|
|---|---|---|
|**输入数据**|有标签数据 (e.g., `图片-猫`)|无标签数据 (e.g., `图片`)|
|**目标**|预测或分类|发现内在结构|
|**好比**|有老师指导的学生|自主探索的探险家|

## 2. 核心任务

无监督学习主要解决三大类问题：聚类、降维和关联规则挖掘。

### 2.1 聚类 (Clustering)

- **目标**: 将数据集中的样本划分为若干个不同的组（或称“簇”），使得**组内成员相似度高，组间成员相似度低**。
    
- **关键算法**:
    
    - **K-均值 (K-Means)**:
        
        1. 预先设定簇的数量 `K`。
            
        2. 随机初始化 `K` 个中心点。
            
        3. **迭代过程**:
            
            - **分配**: 将每个数据点分配给最近的中心点。
                
            - **更新**: 将中心点移动到其所在簇内所有点的平均位置。
                
        4. 重复迭代直到中心点位置稳定。
            
    - **层次聚类 (Hierarchical Clustering)**:
        
        - **优点**: 无需预先指定簇的数量。
            
        - **过程**: 通过不断合并最近的簇，最终形成一个树状结构。
            
        - **可视化**: 使用**树状图 (Dendrogram)** 来展示聚类过程。
            
- **主要应用**:
    
    - `客户分群`: 根据消费行为将客户分组。
        
    - `社交网络分析`: 发现兴趣相投的社群。
        
    - `图像分割`: 将图像中颜色或纹理相似的区域分组。
        

### 2.2 降维 (Dimensionality Reduction)

- **目标**: 在尽可能保留原始数据信息的前提下，用**更少的特征（维度）**来表示数据。好比给数据“瘦身”。
    
- **为什么需要降维?**:
    
    - **可视化**: 将高维数据压缩到2D或3D以便观察。
        
    - **效率**: 减少存储空间和计算时间。
        
    - **去噪**: 消除冗余和不相关的特征。
        
- **关键算法**:
    
    - **主成分分析 (PCA - Principal Component Analysis)**:
        
        - **核心思想**: 寻找一组新的坐标轴（主成分），使得数据在这些轴上的**方差最大化**。
            
        - **过程**: 它将原始特征线性组合，生成一组全新的、按重要性排序的特征，然后保留最重要的前几个。
            
- **主要应用**:
    
    - `人脸识别`: 提取关键面部特征。
        
    - `数据压缩`: 用更少的维度存储信息。
        

### 2.3 关联规则挖掘 (Association Rule Mining)

- **目标**: 发现数据项之间有趣的 **"如果...那么..." (if...then...)** 关系。
    
- **经典案例**: **啤酒与尿布** —— 发现购买尿布的顾客很可能也会购买啤酒。
    
- **关键衡量指标**:
    
    - **支持度 (Support)**:
        
        - `含义`: 某项集在所有交易中出现的频率。
            
        - `公式`: `Support(A, B) = P(A ∩ B)`
            
    - **置信度 (Confidence)**:
        
        - `含义`: 购买了A的交易中，同时购买B的比例。
            
        - `公式`: `Confidence(A ⇒ B) = P(B|A)`
            
    - **提升度 (Lift)**:
        
        - `含义`: 购买A对购买B的概率的提升程度。
            
        - `公式`: `Lift(A ⇒ B) = Confidence(A ⇒ B) / P(B)`
            
        - `解读`: `Lift > 1` 表示正相关（促进），`Lift < 1` 表示负相关（抑制）。
            
- **主要应用**:
    
    - `购物篮分析`: 超市商品摆放优化。
        
    - `推荐系统`: “购买此商品的人也购买了...”。